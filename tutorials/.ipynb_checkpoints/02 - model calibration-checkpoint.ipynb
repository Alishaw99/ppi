{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4bfe6e",
   "metadata": {},
   "source": [
    "# <center>Model calibration</center>\n",
    "\n",
    "Prepared by Omar A. Guerrero (oguerrero@turing.ac.uk, <a href=\"https://twitter.com/guerrero_oa\">@guerrero_oa</a>)\n",
    "\n",
    "In this tutorial I will calibrate the free parameters of PPI's model. First, I will load all the data that we have prepared in the previous tutorials. Then, I extract the relevant information and put it in adequate data structures. Finally, I run the calibration function and save the results with the parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077e294",
   "metadata": {},
   "source": [
    "## Importing Python libraries to manipulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9d93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56449b",
   "metadata": {},
   "source": [
    "## Importing PPI functions\n",
    "\n",
    "In this tutorial, I will import the PPI source code directly from its repository. This means that I will place a request to GitHub, download the `ppi.py` file, and copy it locally into the folder where these tutorials are saved. Then, we will import ppi. This approach is useful if you want to run this tutorial in a cloud computing service.\n",
    "\n",
    "An alternative would be to manually copy the `ppi.py` file into the folder where this tutorial is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88cfa647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # the Python library that helps placing requests to websites\n",
    "url = 'https://raw.githubusercontent.com/oguerrer/ppi/main/source_code/ppi.py'\n",
    "r = requests.get(url)\n",
    "with open('ppi.py', 'w') as f:\n",
    "    f.write(r.text)\n",
    "import ppi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2963d9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f642dd32",
   "metadata": {},
   "source": [
    "### Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e07398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indis = pd.read_csv('https://raw.githubusercontent.com/oguerrer/ppi/main/tutorials/clean_data/data_indicators.csv')\n",
    "\n",
    "N = len(df_indis) # number of indicators\n",
    "I0 = df_indis.I0.values # initial values\n",
    "IF = df_indis.IF.values # final values\n",
    "success_rates = df_indis.successRates.values # success rates\n",
    "R = df_indis.instrumental # instrumental indicators\n",
    "qm = df_indis.qm.values # quality of monitoring\n",
    "rl = df_indis.rl.values # quality of the rule of law\n",
    "indis_index = dict([(code, i) for i, code in enumerate(df_indis.seriesCode)]) # used to build the network matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8cf95",
   "metadata": {},
   "source": [
    "### Interdependency network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb786f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net = pd.read_csv('https://raw.githubusercontent.com/oguerrer/ppi/main/tutorials/clean_data/data_network.csv')\n",
    "\n",
    "A = np.zeros((N, N)) # adjacency matrix\n",
    "for index, row in df_net.iterrows():\n",
    "    i = indis_index[row.origin]\n",
    "    j = indis_index[row.destination]\n",
    "    w = row.weight\n",
    "    A[i,j] = w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69236e0",
   "metadata": {},
   "source": [
    "### Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9779e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = pd.read_csv('https://raw.githubusercontent.com/oguerrer/ppi/main/tutorials/clean_data/data_expenditure.csv')\n",
    "\n",
    "Bs = df_exp.values[:,1::] # disbursement schedule (assumes that the expenditure programmes are properly sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e8a07",
   "metadata": {},
   "source": [
    "### Budget-indicator mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "007a8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rela = pd.read_csv('https://raw.githubusercontent.com/oguerrer/ppi/main/tutorials/clean_data/data_relational_table.csv')\n",
    "\n",
    "B_dict = {} # PPI needs the relational table in the form of a Python dictionary\n",
    "for index, row in df_rela.iterrows():\n",
    "    B_dict[indis_index[row.seriesCode]] = [programme for programme in row.values[1::][row.values[1::].astype(str)!='nan']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c410c35",
   "metadata": {},
   "source": [
    "## Calibrate\n",
    "\n",
    "Now I run the calibration function to show that it works. Before that, let me explain a couple of new inputs that the user needs to provide:\n",
    "\n",
    "* <strong>threshold</strong>: How well should the model be fit.\n",
    "* <strong>parallel_processes</strong>: The number of processes (workers) to be ran in parallel.\n",
    "* <strong>verbose</strong>: Whether to print or not the outputs as the calibration progresses.\n",
    "* <strong>low_precision_counts</strong>: The number of iterations that use few Monte Carlo simulations.\n",
    "\n",
    "The <strong>threshold</strong> parameter indicates the quality of the goodness of fit. More specifically, how good should the worst-fitted indicator be. The best possible fit is close to 1, but cannot be exactly 1 due to the stochasticity of the model. The higher the threshold, the mode Monte Carlo simulations are needed and, thus, the more time and computational resources are needed to complete the calibration.\n",
    "\n",
    "Parameter <strong>parallel_processes</strong> is used to enhance efficiency. Since each Monte Carlo simulation is independent of each other, this workload can be distributed across multiple cores or processors. Today, most personal devices have the capability of handling this distributed load, so here I show how to calibrate the model using 4 parallel processes. It is recommended that you know how many cores or processors your equipment has, and that <strong>parallel_processes</strong> does not exceed that number. Otherwise, the performance of the calibration may be sub-optimal.\n",
    "\n",
    "Finally, the <strong>low_precision_counts</strong> parameter helps accelerating the calibration. At the beginning of the calibration, the algorithm proposes a random set of parameters for the model. Because this proposal is unrelated to the true parameters, the errors tend to be large. In the presence of large errors, one can improve the goodness of fit without needind too much precision in each evaluation (i.e., without running too many Monte Carlo simulations). Hence, this parameter determines how many low-precision iterations of the algorithm should be run before proceeding to the high-precision ones. This accelerates the calibration procedure substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970d585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 .    Worst goodness of fit: -884997.9999982293\n",
      "Iteration: 2 .    Worst goodness of fit: -577124.9999988454\n",
      "Iteration: 3 .    Worst goodness of fit: -258749.99999948233\n",
      "Iteration: 4 .    Worst goodness of fit: -69046.87499986183\n",
      "Iteration: 5 .    Worst goodness of fit: -16415.96874996715\n",
      "Iteration: 6 .    Worst goodness of fit: -18878.906249962227\n",
      "Iteration: 7 .    Worst goodness of fit: -9081.496093731826\n",
      "Iteration: 8 .    Worst goodness of fit: -7633.300781234727\n",
      "Iteration: 9 .    Worst goodness of fit: -1031.6051151677336\n",
      "Iteration: 10 .    Worst goodness of fit: -2239.5629882767694\n",
      "Iteration: 11 .    Worst goodness of fit: -1275.3666381810376\n",
      "Iteration: 12 .    Worst goodness of fit: -1229.164123532697\n",
      "Iteration: 13 .    Worst goodness of fit: -245.50137329052043\n",
      "Iteration: 14 .    Worst goodness of fit: -409.83724594034214\n",
      "Iteration: 15 .    Worst goodness of fit: -119.75190448736628\n",
      "Iteration: 16 .    Worst goodness of fit: -222.1255302424755\n",
      "Iteration: 17 .    Worst goodness of fit: -123.2389103171704\n",
      "Iteration: 18 .    Worst goodness of fit: -66.87229871736497\n",
      "Iteration: 19 .    Worst goodness of fit: -31.399486914210257\n",
      "Iteration: 20 .    Worst goodness of fit: -21.61251101638523\n",
      "Iteration: 21 .    Worst goodness of fit: -7.981350507567223\n",
      "Iteration: 22 .    Worst goodness of fit: -9.548275382238893\n",
      "Iteration: 23 .    Worst goodness of fit: -0.9799693147592254\n",
      "Iteration: 24 .    Worst goodness of fit: -3.634737659005623\n",
      "Iteration: 25 .    Worst goodness of fit: -0.21760416589107012\n",
      "Iteration: 26 .    Worst goodness of fit: -1.1325445170233377\n",
      "Iteration: 27 .    Worst goodness of fit: -0.018312154096398414\n",
      "Iteration: 28 .    Worst goodness of fit: 0.05662597093825528\n",
      "Iteration: 29 .    Worst goodness of fit: 0.09127827311527037\n",
      "Iteration: 30 .    Worst goodness of fit: 0.21534062948227006\n",
      "Iteration: 31 .    Worst goodness of fit: 0.19942851401644224\n",
      "Iteration: 32 .    Worst goodness of fit: 0.03647090825968513\n",
      "Iteration: 33 .    Worst goodness of fit: -1.0520784634726463\n",
      "Iteration: 34 .    Worst goodness of fit: 0.28545602586908825\n",
      "Iteration: 35 .    Worst goodness of fit: 0.12881870316428057\n",
      "Iteration: 36 .    Worst goodness of fit: 0.07066451258855677\n",
      "Iteration: 37 .    Worst goodness of fit: 0.15590599957581885\n",
      "Iteration: 38 .    Worst goodness of fit: 0.34889856883246895\n",
      "Iteration: 39 .    Worst goodness of fit: 0.25210173010900605\n",
      "Iteration: 40 .    Worst goodness of fit: 0.29746703117789475\n",
      "Iteration: 41 .    Worst goodness of fit: 0.42128619464519457\n",
      "Iteration: 42 .    Worst goodness of fit: 0.029305370762082394\n",
      "Iteration: 43 .    Worst goodness of fit: 0.25240005015723965\n",
      "Iteration: 44 .    Worst goodness of fit: -0.8738309851282129\n",
      "Iteration: 45 .    Worst goodness of fit: 0.25451092648172446\n",
      "Iteration: 46 .    Worst goodness of fit: 0.13685651196417337\n",
      "Iteration: 47 .    Worst goodness of fit: 0.2224936364509844\n",
      "Iteration: 48 .    Worst goodness of fit: 0.3122292952334287\n",
      "Iteration: 49 .    Worst goodness of fit: 0.31509933044985083\n",
      "Iteration: 50 .    Worst goodness of fit: 0.3774890123661869\n",
      "Iteration: 51 .    Worst goodness of fit: 0.4959456763791653\n",
      "Iteration: 52 .    Worst goodness of fit: 0.2324542624162519\n"
     ]
    }
   ],
   "source": [
    "T = Bs.shape[1]\n",
    "parallel_processes = 4 # number of cores to use\n",
    "threshold = 0.6 # the quality of the calibration (I choose a medium quality for illustration purposes)\n",
    "low_precision_counts = 50 # number of low-quality iterations to accelerate the calibration\n",
    "\n",
    "parameters = ppi.calibrate(I0, IF, success_rates, A=A, R=R, qm=qm, rl=rl, Bs=Bs, B_dict=B_dict,\n",
    "              T=T, threshold=threshold, parallel_processes=parallel_processes, verbose=True,\n",
    "             low_precision_counts=low_precision_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2572ad1",
   "metadata": {},
   "source": [
    "## Calibration outputs\n",
    "\n",
    "The output of the calibration function is a matrix with the following columns:\n",
    "\n",
    "* <strong>alpha</strong>: the parameters related to structural constraints\n",
    "* <strong>alpha_prime</strong>: the parameters related to structural costs\n",
    "* <strong>beta</strong>: the parameters related to the probability of success\n",
    "* <strong>T</strong>: the number of simulation periods\n",
    "* <strong>error_alpha</strong>: the errors associated to the parameters $\\alpha$ and $\\alpha'$\n",
    "* <strong>error_beta</strong>: the errors associated to the parameters $\\beta$\n",
    "* <strong>GoF_alpha</strong>: the goodness-of-fit associated to the parameters $\\alpha$ and $\\alpha'$\n",
    "* <strong>GoF_beta</strong>: the goodness-of-fit associated to the parameters $\\beta$\n",
    "\n",
    "The top row of this matrix contains the column names, so we just need to transform these data into a DataFrame to export it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b9a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params = pd.DataFrame(parameters[1::], columns=parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2426f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a69b6e",
   "metadata": {},
   "source": [
    "## Save parameters data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbf495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params.to_csv('clean_data/parameters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c76e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
