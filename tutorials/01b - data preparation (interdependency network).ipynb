{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8ce9da",
   "metadata": {},
   "source": [
    "# Data preparation â€“ interdependency networks\n",
    "\n",
    "Prepared by Omar A. Guerrero (oguerrero@turing.ac.uk, @guerrero_oa)\n",
    "\n",
    "In the literature related to the Sustainable Development GOals (SDGs), much attention has been given to interdependency networks between SDGs, targets, or development indicators. On of the features of PPI is its ability to take into account such networks as an exogenous variable meant to preserve certain structure in the co-movenent of the indicators. This network is considered exogenous because it is a stylised fact of the system under study, not a causal account of the relationship between the indicators. While many studies attempt at making causal claims from such objects, we have shown (in the book and in multiple publications) that such statements cannot be causal (see https://doi.org/10.1016/j.im.2020.103342 for an example). Thus, the aim in this tutorial is to simply show how to prepare the data for the network input of PPI.\n",
    "\n",
    "In the book, as in most of PPI's studies, we have employed a method called `sparsebn` (see http://doi.org/10.18637/jss.v091.i11). However, for the sake of simplicity in these tutorials, let us employ a simple correlation approach to construct the network. First, we will lead the clean indicator data. Then, we will estimate pairwise correlations. Next, we will filter out edges using an arbitrary threshold criterion. Finally, we will structure the data and export it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61275600",
   "metadata": {},
   "source": [
    "## Import the necessary python libraries to manipulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1497005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ec449",
   "metadata": {},
   "source": [
    "## Import the raw development indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79b799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/oguerrer/ppi/main/tutorials/clean_data/data_indicators.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cebfcc5",
   "metadata": {},
   "source": [
    "## Construct a matrix with pairwise Pearson correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "558e7abe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, rowj \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m!=\u001b[39mj:\n\u001b[0;32m----> 8\u001b[0m         M[i,j] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrcoef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrowi\u001b[49m\u001b[43m[\u001b[49m\u001b[43myears\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowj\u001b[49m\u001b[43m[\u001b[49m\u001b[43myears\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2821\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[1;32m   2818\u001b[0m     \u001b[38;5;66;03m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias and ddof have no effect and are deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2820\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m-> 2821\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2823\u001b[0m     d \u001b[38;5;241m=\u001b[39m diag(c)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2656\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2654\u001b[0m         w \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m aweights\n\u001b[0;32m-> 2656\u001b[0m avg, w_sum \u001b[38;5;241m=\u001b[39m \u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2657\u001b[0m w_sum \u001b[38;5;241m=\u001b[39m w_sum[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2659\u001b[0m \u001b[38;5;66;03m# Determine the normalization\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:530\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    527\u001b[0m     avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(a, wgt, dtype\u001b[38;5;241m=\u001b[39mresult_dtype)\u001b[38;5;241m.\u001b[39msum(axis)\u001b[38;5;241m/\u001b[39mscl\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m returned:\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mscl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m!=\u001b[39m avg\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m    531\u001b[0m         scl \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbroadcast_to(scl, avg\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg, scl\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "N = len(data)\n",
    "M = np.zeros((N, N))\n",
    "years = [column_name for column_name in data.columns if str(column_name).isnumeric()]\n",
    "\n",
    "for i, rowi in data.iterrows():\n",
    "    for j, rowj in data.iterrows():\n",
    "        if i!=j:\n",
    "            M[i,j] = np.corrcoef(rowi[years].values, rowj[years].values)[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowj[years].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1289e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(data[years].values, axis=1)!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06918cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
