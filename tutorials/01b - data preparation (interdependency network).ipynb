{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b7dab01",
   "metadata": {},
   "source": [
    "# Data preparation â€“ interdependency networks\n",
    "\n",
    "Prepared by Omar A. Guerrero (oguerrero@turing.ac.uk, @guerrero_oa)\n",
    "\n",
    "In the literature related to the Sustainable Development Goals (SDGs), much attention has been given to interdependency networks between SDGs, targets, or development indicators. On of the features of PPI is its ability to take into account such networks as an exogenous variable meant to preserve certain structure in the co-movement of the indicators. This network is considered exogenous because it is a stylised fact of the system under study, not a causal account of the relationship between the indicators. While many studies attempt at making causal claims from such objects, we have shown (in the book and in multiple publications) that such statements cannot be causal (see https://doi.org/10.1016/j.im.2020.103342 for an example and for a list of potential methods). Thus, the aim in this tutorial is to simply show how to prepare the data for the network input of PPI.\n",
    "\n",
    "In the book, as in most of PPI's studies, we have employed a method called `sparsebn` (see http://doi.org/10.18637/jss.v091.i11). However, for the sake of simplicity in these tutorials, let us employ a simple correlation approach to construct the network. First, we will lead the clean indicator data. Then, we will estimate pairwise correlations between the changes of two time series, with one of them in lagged values. This allows constructing a directed asymmetric network. Next, we will filter out edges using an arbitrary threshold criterion. Finally, we will structure the data and export it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a377d",
   "metadata": {},
   "source": [
    "## Import the necessary python libraries to manipulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f033da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d138d7",
   "metadata": {},
   "source": [
    "## Import the raw development indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3097fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/oguerrer/ppi/main/tutorials/clean_data/data_indicators.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a8e53",
   "metadata": {},
   "source": [
    "## Construct a matrix with pairwise Pearson correlations\n",
    "\n",
    "The directionality of the edges is from row to column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc363d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data)\n",
    "M = np.zeros((N, N))\n",
    "years = [column_name for column_name in data.columns if str(column_name).isnumeric()]\n",
    "\n",
    "for i, rowi in data.iterrows():\n",
    "    for j, rowj in data.iterrows():\n",
    "        if i!=j:\n",
    "            serie1 = rowi[years].values.astype(float)[1::]\n",
    "            serie2 = rowj[years].values.astype(float)[0:-1]\n",
    "            change_serie1 = serie1[1::] - serie1[0:-1]\n",
    "            change_serie2 = serie2[1::] - serie2[0:-1]\n",
    "            if not np.all(change_serie1 == change_serie1[0]) and not np.all(change_serie2 == change_serie2[0]):\n",
    "                M[i,j] = np.corrcoef(change_serie1, change_serie2)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a58dbad",
   "metadata": {},
   "source": [
    "## Filter edges that have a weight of magnitude lower than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59c522a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[np.abs(M) < 0.5] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a461f0",
   "metadata": {},
   "source": [
    "## Save the network as a list of edges using the indicators' ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "071a5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = data.seriesCode.values\n",
    "edge_list = []\n",
    "for i, j in zip(np.where(M!=0)[0], np.where(M!=0)[1]):\n",
    "    edge_list.append( [ids[i], ids[j], M[i,j]] )\n",
    "df = pd.DataFrame(edge_list, columns=['origin', 'destination', 'weight'])\n",
    "df.to_csv('clean_data/data_network.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b50f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
